# Towards Robust LLMs: an Adversarial Robustness Measurement Framework
This project is the code for the paper - [Towards Robust LLMs: an Adversarial Robustness Measurement Framework](https://arxiv.org/pdf/2504.17723).

This project contains four sub-projects:

1. Validating RoMA against Formal Verification -  See the [README](validate-RoMA-with-exact-count/) for more details.
2. Measuring LLM Embedding Robustness with RoMA - See the   [README](llm-embedding-robustness-with-RoMA/) for more details.
3. LLM Categorial Robustness - See the  [README](llm-categorial-robustness/) for more details.
4. Measuring LLM Typo Robustness with RoMA - See the [README](llm-typo-robustness-with-RoMA/) for more details.

# Citation:

To cite this work please use the following format:

      @misc{LeAsKa25,
      title={Towards Robust LLMs: an Adversarial Robustness Measurement Framework},
      author={Levy, Natan and Ashrov, Adiel and Katz, Guy},
      note = {{Technical Report}. \url{https://arxiv.org/pdf/2504.17723}},
      year={2025}
      }

Good Luck,

Adiel & Nati
